<html>
<head>
<meta charset="UTF-8">
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="jquery_plantuml.js"></script>
<!-- rawdeflate.js is implicity used by jquery_plantuml.js -->
</head>

<body>
<p>Stuff goes bad. Erlang in anger</p>
<p>Contents</p>
<p>Introduction</p>
<p>Writing Applications</p>
<ol>
	<li>
	How to Dive into a Code Base
		<ol>
		<li>Raw Erlang </li>
		<li>
		OTP Applications
		<ol>
			<li>Library Applications</li>
			<li>Regular Applications</li>
			<li>Dependencies</li>
			</ol>
		</li>
		<li>OTP Releases</li>
		<li>Exercises</li>
		</ol>
	</li>
	<li>
	Building Open Source Erlang Software
		<ol>
		<li>Project Structure </li>
			<ol>
			<li>OTP Applications</li>
			<li>OTP Releases</li>
			</ol>
		<li>Supervisors and start_link Semantics</li>
			<ol>
			<li>It’s About the Guarantees</li>
			<li>Side Effects</li>
			<li>Example: Initializing without guaranteeing connections</li>
			<li>In a nutshell</li>
			<li>Application Strategies</li>
			</ol>
		<li> Exercises</li>
		</ol>
	</li>
	<li>
	Planning for Overload
	<ol>
		<li>
			Common Overload Sources
			<ol>
			<li>error_logger Explodes</li>
			<li>Locks and Blocking Operations</li>
			<li>Unexpected Messages</li>
			</ol>
			</li>
			
		</li>
	
		<li>
		Restricting Input
		<ol>
			<li>How Long Should a Time Out Be</li>
			<li>Asking For Permission</li>
			<li>What Users See</li>
			</ol>
		</li>
		<li>
		Discarding Data
			<ol>
			<li>Random Drop</li>
			<li>Queue Buffers</li>
			<li>Stack Buffers</li>
			<li>Time-Sensitive Buffers</li>
			<li>Dealing With Constant Overload</li>
			<li>How Do You Drop</li>
			</ol>
		</li>
		<li>Exercises</li>
		
		</ol>
	</ol>

	<p>II Diagnosing Applications</p>
<ol>
	<li>
	Connecting to Remote Nodes
	<ol>
		<li>Job Control Mode</li>
		<li>Remsh</li>
		<li>SSH Daemon</li>
		<li>Named Pipes</li>
		<li>Exercises</li>
	</ol>
	</li>
	<li>
	Runtime Metrics
	<ol>
		<li>Global View</li>
			<ol>
			<li>Memory</li>
			<li>CPU</li>
			<li>Processes</li>
			<li>Ports</li>
			</ol>
		<li>Digging In</li>
		<ol>
			<li>Processes</li>
			<li>OTP Processes</li>
			<li>Ports</li>
			</ol>
		<li>Exercises</li>
		</ol>
		</li>

		<li>

	Reading Crash Dumps
		<ol>
		<li>General View</li>
		<li>Full Mailboxes</li>
		<li>Too Many (or too few) Processes</li>
		<li>Too Many Ports</li>
		<li>Can’t Allocate Memory</li>
		<li>Exercises</li>
		</ol>
		</li>
		<li>

	Memory Leaks
	<ol>
		<li>Common Sources of Leaks
			<ol>
			<li>Atom</li>
			<li>Binary</li>
			<li>Code</li>
			<li>ETS</li>
			<li>Processes</li>
			<li>Nothing in Particular</li>
			</ol>
		<li>Binaries</li>
		<ol>
			<li>Detecting Leaks</li>
			<li>Fixing Leaks</li>
			</ol>
		<li>Memory Fragmentation</li>
		<ol>
			<li>Finding Fragmentation</li>
			<li>Erlang’s Memory Model</li>
			<li>Fixing Memory Fragmentation with a Different Allocation Strategy</li>
			</ol>
		<li>Exercises</li>
		</ol>
		</li>
		
		<li>
	CPU and Scheduler Hogs
		<ol>
		<li>Profiling and Reduction Counts</li>
		<li>System Monitors</li>
			<ol>
			<li>Suspended Ports</li>
			</ol>
		<li>Exercises</li>
		</ol>
		</li>
		<li>
	Tracing
	<ol>
		<li>Tracing Principles</li>
		<li>Tracing with Recon</li>
		<li>Example Sessions</li>
		<li>Exercises</li>
		</ol>
		</li>
		<li>
	Conclusion
	</li>

	</ol>

	<hr>
<h2>Introduction</h2>
<h3>On Running Software</h3>

<p>
There’s something rather unique in Erlang in how it approaches failure compared to most
other programming languages. There’s this common way of thinking where the language,
programming environment, and methodology do everything possible to prevent errors.
Something going wrong at run-time is something that needs to be prevented, and if it
cannot be prevented, then it’s out of scope for whatever solution people have been thinking
about.
</p>

<p>
The program is written once, and after that, it’s off to production, whatever may happen
there. If there are errors, new versions will need to be shipped.
</p>

<p>Erlang, on the other hand, takes the approach that failures will happen no matter what,
whether they’re developer-, operator-, or hardware-related. It is rarely practical or even
possible to get rid of all errors in a program or a system.1 If you can deal with some errors
rather than preventing them at all cost, then most undefined behaviours of a program can
go in that "deal with it" approach.</p>

<p>This is where the "Let it Crash"2 idea comes from: Because you can now deal with
failure, and because the cost of weeding out all of the complex bugs from a system before
it hits production is often prohibitive, programmers should only deal with the errors they
know how to handle, and leave the rest for another process (a supervisor) or the virtual
machine to deal with.
</p>
<p>
Given that most bugs are transient3, simply restarting processes back to a state known
to be stable when encountering an error can be a surprisingly good strategy.
</p>

<p>Erlang is a programming environment where the approach taken is equivalent to the
human body’s immune system, whereas most other languages only care about hygiene to
make sure no germ enters the body. Both forms appear extremely important to me. Almost
every environment offers varying degrees of hygiene. Nearly no other environment offers
the immune system where errors at run time can be dealt with and seen as survivable.
</p>

<p>
Because the system doesn’t collapse the first time something bad touches it, Erlang/OTP
also allows you to be a doctor. You can go in the system, pry it open right there in production,
carefully observe everything inside as it runs, and even try to fix it interactively.
To continue with the analogy, Erlang allows you to perform extensive tests to diagnose the
problem and various degrees of surgery (even very invasive surgery), without the patients
needing to sit down or interrupt their daily activities.
</p>


<p>
This book intends to be a little guide about how to be the Erlang medic in a time of
war. It is first and foremost a collection of tips and tricks to help understand where failures
come from, and a dictionary of different code snippets and practices that helped developers
debug production systems that were built in Erlang.
</p>

<sub>

<br/>1life-critical systems are usually excluded from this category
<br/>2Erlang people now seem to favour "let it fail", given it makes people far less nervous.
<br/>3131 out of 132 bugs are transient bugs (they’re non-deterministic and go away when you look at them,
and trying again may solve the problem entirely), according to Jim Gray in Why Do Computers Stop and
What Can Be Done About It?
</sub>
<h3>Who is this for?</h3>

<p>This book is not for beginners. There is a gap left between most tutorials, books, training
sessions, and actually being able to operate, diagnose, and debug running systems once
they’ve made it to production. There’s a fumbling phase implicit to a programmer’s learning
of a new language and environment where they just have to figure how to get out of the
guidelines and step into the real world, with the community that goes with it.
</p>

<p>
This book assumes that the reader is proficient in basic Erlang and the OTP framework.
Erlang/OTP features are explained as I see fit — usually when I consider them tricky —
and it is expected that a reader who feels confused by usual Erlang/OTP material will have
an idea of where to look for explanations if necessary4.
</p>

<p>
	What is not necessarily assumed is that the reader knows how to debug Erlang software,
dive into an existing code base, diagnose issues, or has an idea of the best practices about
deploying Erlang in a production environment5
</p>

<h3>How To Read This Book</h3>

<p>This book is divided in two parts.</p>
<p>Part I focuses on how to write applications. It includes how to dive into a code base
(Chapter 1), general tips on writing open source Erlang software (Chapter 2), and how to
plan for overload in your system design (Chapter 3).</p>
<p>Part II focuses on being an Erlang medic and concerns existing, living systems. It
contains instructions on how to connect to a running node (Chapter 4), and the basic
runtime metrics available (Chapter 5). It also explains how to perform a system autopsy
using a crash dump (Chapter 6), how to identify and fix memory leaks (Chapter 7), and how to find runaway CPU usage (Chapter 8). The final chapter contains instructions on
how to trace Erlang function calls in production using recon6 to understand issues before
they bring the system down (Chapter 9).</p>
<sub>
<br/>4I do recommend visiting Learn You Some Erlang or the regular Erlang Documentation if a free resource
is required
<br/>5Running Erlang in a screen or tmux session is not a deployment strategy.
</sub>
<p>Each chapter is followed up by a few optional exercises in the form of questions or
hands-on things to try if you feel like making sure you understood everything, or if you
want to push things further.</p>
<sub>
	6http://ferd.github.io/recon/ — a library used to make the text lighter, and with generally productionsafe
functions.
</sub>
<hr/>
<h1> Part I </h1>
<h1> Writing Applications </h1>

<h2> Chapter 1 </h2>
 <h3> How to Dive into a Code Base </h3>

 <p>"Read the source" is one of the most annoying things to be told, but dealing with Erlang
programmers, you’ll have to do it often. Either the documentation for a library will be
incomplete, outdated, or just not there. In other cases, Erlang programmers are a bit
similar to Lispers in that they will tend to write libraries that will solve their problems and
not really test or try them in other circumstances, leaving it to you to extend or fix issues
that arise in new contexts.</p>
<p>It’s thus pretty much guaranteed you’ll have to go dive in some code base you know
nothing about, either because you inherited it at work, or because you need to fix it or
understand it to be able to move forward with your own system. This is in fact true of
most languages whenever the project you work on is not one you designed yourself.</p>

<p>There are three main types of Erlang code bases you’ll encounter in the wild: raw Erlang
code bases, OTP applications, and OTP releases. In this chapter, we’ll look at each of these
and try to provide helpful tips on navigating them.</p>

<h4>Raw Erlang</h4>
<p>If you encounter a raw Erlang code base, you’re pretty much on your own. These rarely
follow any specific standard, and you have to dive in the old way to figure out whatever
happens in there.</p>
<p>This means hoping for a <b>README.md</b> file or something similar that can point to an entry
point in the application, and going from there, or hoping for some contact information that
can be used to ask questions to the author(s) of the library.</p>

<p>Fortunately, you should rarely encounter raw Erlang in the wild, and they are often
beginner projects, or awesome projects that were once built by Erlang beginners and now
need a serious rewrite. In general, the advent of tools such as rebar1 made it so most
people use OTP Applications.</p>

<sub>
	1https://github.com/rebar/rebar/ — a build tool briefly introduced in Chapter 2
</sub>

<h4>OTP Applications</h4>
<p>Figuring out OTP applications is usually rather simple. They usually all share a directory
structure that looks like:</p>

<div class="code">
doc/
ebin/
src/
test/
LICENSE.txt
README.md
rebar.config
</div>

<p>There might be slight differences, but the general structure will be the same.</p>

<p>Each OTP application should contain an app file, either ebin/<AppName>.app or more
often, src/<AppName>.app.src2. There are two main varieties of app files:</p>

<div style="code"> 
{application, useragent, [
{description, "Identify browsers & OSes from useragent strings"},
{vsn, "0.1.2"},
{registered, []},
{applications, [kernel, stdlib]},
{modules, [useragent]}
]}.
</div>
<p>And.
</p>
<div style="code" >
	{application, dispcount, [
{description, "A dispatching library for resources and task "
"limiting based on shared counters"},
{vsn, "1.0.0"},
{applications, [kernel, stdlib]},
{registered, []},
{mod, {dispcount, []}},
{modules, [dispcount, dispcount_serv, dispcount_sup,
dispcount_supersup, dispcount_watcher, watchers_sup]}
]}.

</div>

<p>This first case is called a <i>library application</i>, while the second case is a regular <i>application</i>.</p>

<sub>
2A build system generates the final file that goes in ebin. Note that in these cases, many
src/<AppName>.app.src files do not specify modules and let the build system take care of it.
</sub>

<h5>Library Applications</h5>
<p>Library applications will usually have modules named appname _something, and one module
named appname . This will usually be the interface module that’s central to the library and
contains a quick way into most of the functionality provided.</p>
<p>
	By looking at the source of the module, you can figure out how it works with little
effort: If the module adheres to any given behaviour (gen_server, gen_fsm, etc.), you’re
most likely expected to start a process under one of your own supervisors and call it that
way. If no behaviour is included, then you probably have a functional, stateless library on
your hands. For this case, the module’s exported functions should give you a quick way to
understand its purpose.
</p>

<h5>Regular Applications</h5>
<p>For a regular OTP application, there are two potential modules that act as the entry point:</p>
<ol>
	<li>appname</li>
	<li>appname _app</li>
</ol>
<p>The first file should be similar in use to what we had in a library application (an entry
point), while the second one will implement the application behaviour, and will represent
the top of the application’s process hierarchy. In some cases the first file will play both
roles at once.</p>

<p>If you plan on simply adding the application as a dependency to your own app, then
look inside appname for details and information. If you need to maintain and/or fix the
application, go for appname _app instead.</p>

<p>The application will start a top-level supervisor and return its pid. This top-level
supervisor will then contain the specifications of all the child processes it will start on its
own3.</p>

<p>The higher a process resides in the tree, the more likely it is to be vital to the survival of
the application. You can also estimate how important a process is by the order it is started
(all children in the supervision tree are started in order, depth-first). If a process is started
later in the supervision tree, it probably depends on processes that were started earlier.</p>

<p>Moreover, worker processes that depend on each other within the same application (say,
a process that buffers socket communications and relays them to a finite-state machine in
charge of understanding the protocol) are likely to be regrouped under the same supervisor
and to fail together when something goes wrong. This is a deliberate choice, as it is usually
simpler to start from a blank slate, restarting both processes, rather than trying to figure
out how to recuperate when one or the other loses or corrupts its state.</p>

<sub>
	3In some cases, the supervisor specifies no children: they will either be started dynamically by some
function of the API or in a start phase of the application, or the supervisor is only there to allow OTP
environment variables (in the env tuple of the app file) to be loaded.
</sub>

<p>The supervisor restart strategy reflects the relationship between processes under a supervisor:</p>
<ul>
<li>
<b>one_for_one</b> and <b>simple_one_for_one</b> are used for processes that are not dependent
upon each other directly, although their failures will collectively be counted towards
total application shutdown4.
</li>
<li><b>rest_for_one</b> will be used to represent processes that depend on each other in a
linear manner.</li>
<li><b>one_for_all</b> is used for processes that entirely depend on each other.</li>
</ul>

<p>This structure means it is easiest to navigate OTP applications in a top-down manner
by exploring supervision subtrees.</p>

<p>For each worker process supervised, the behaviour it implements will give a good clue
about its purpose:</p>

<ul>
	<li>a <b>gen_server</b> holds resources and tends to follow client/server patterns (or more
generally, request/response patterns)</li>
	<li>a <b>gen_fsm</b> will deal with a sequence of events or inputs and react depending on them,
as a Finite State Machine. It will often be used to implement protocols.</li>
	<li>a <b>gen_event</b> will act as an event hub for callbacks, or as a way to deal with notifications
of some sort.</li>
</ul>
<p>All of these modules will contain the same kind of structure: exported functions that
represent the user-facing interface, exported functions for the callback module, and private
functions, usually in that order.</p>

<p>Based on their supervision relationship and the typical role of each behaviour, looking
at the interface to be used by other modules and the behaviours implemented should reveal
a lot of information about the program you’re diving into.</p>

<h5>Dependencies</h5>

<p>All applications have dependencies5, and these dependencies will have their own dependencies.
OTP applications usually share no state between them, so it’s possible to know what
bits of code depend on what other bits of code by looking at the app file only, assuming the
developer wrote them in a mostly correct manner. Figure 1.1 shows a diagram that can be
generated from looking at app files to help understand the structure of OTP applications.</p>

<p>Using such a hierarchy and looking at each application’s short description might be
helpful to draw a rough, general map of where everything is located. To generate a similar
diagram, find recon’s script directory and call escript script/app_deps.erl6. Similar hierarchies can be found using the observer7 application, but for individual supervision
trees. Put together, you may get an easy way to find out what does what in the code base.</p>
<sub>
<br/>4Some developers will use one_for_one supervisors when rest_for_one is more appropriate. They
require strict ordering to boot correctly, but forget about said order when restarting or if a predecessor
dies.
<br/>5At the very least on the kernel and stdlib applications	
<br/>6This script depends on graphviz
</sub>
<p></p>
<img src="images/riak_arc.png">
<p>Figure 1.1: Dependency graph of riak_cs, Basho’s open source cloud library. The graph
ignores dependencies on common applications like kernel and stdlib. Ovals are applications,
rectangles are library applications.</p>

<h3>OTP Releases</h3>
<p>OTP releases are not a lot harder to understand than most OTP applications you’ll encounter
in the wild. A release is a set of OTP applications packaged in a production-ready
manner so it boots and shuts down without needing to manually call application:start/2
for any app. Of course there’s a bit more to releases than that, but generally, the same
discovery process used for individual OTP applications will be applicable here.</p>

<p>You’ll usually have a file similar to the configuration files used by systools or reltool,
which will state all applications part of the release and a few8 options regarding their
packaging. To understand them, I recommend reading existing documentation on them. If
you’re lucky, the project may be using relx9, an easier tool that was officially released in
early 2014.</p>

<h3>1.4 Exercises</h3>
<h4>Review Questions</h4>
<ol>
	<li>How do you know if a code base is an application? A release?</li>
	<li>What differentiates an application from a library application?</li>
	<li>What can be said of processes under a one_for_all scheme for supervision?</li>
	<li>Why would someone use a gen_fsm behaviour over a gen_server?</li>
</ol>
<h4>Hands-on</h4>
<p>Download the code at https://github.com/ferd/recon_demo. This will be used as a test
bed for exercises throughout the book. Given you are not familiar with the code base yet,
let’s see if you can use the tips and tricks mentioned in this chapter to get an understanding
of it.</p>

<ol>
	<li>Is this application meant to be used as a library? A standalone system?</li>
	<li>What does it do?</li>
	<li>Does it have any dependencies? What are they?</li>
	<li>The app’s README mentions being non-deterministic. Can you prove if this is true?
How?</li>
	<li>Can you express the dependency chain of applications in there? Generate a diagram
of them?</li>
	<li>Can you add more processes to the main application than those described in the
README?</li>

</ol>

<h2>Chapter 2</h2>
<h2>Building Open Source Erlang
Software</h2>
<p>Most Erlang books tend to explain how to build Erlang/OTP applications, but few of them
go very much in depth about how to integrate with the Erlang community doing Open
Source work. Some of them even avoid the topic on purpose. This chapter dedicates itself
to doing a quick tour of the state of affairs in Erlang.</p>
<p>OTP applications are the vast majority of the open source code people will encounter.
In fact, many people who would need to build an OTP release would do so as one umbrella
OTP application.</p>

<p>If what you’re writing is a stand-alone piece of code that could be used by someone
building a product, it’s likely an OTP application. If what you’re building is a product
that stands on its own and should be deployed by users as-is (or with a little configuration),
what you should be building is an OTP release.</p>

<p>The main build tools supported are rebar and erlang.mk. The former is a portable
Erlang script that will be used to wrap around a lot of standard functionality and add its
own, while the latter is a very fancy makefile that does a bit less, but tends to be faster
when it comes to compiling. In this chapter, I’ll mostly focus on using rebar to build
things, given it’s the ad-hoc standard, is well-established, and erlang.mk applications tend
to also be supported by rebar as dependencies.</p>

<h3>Project Structure</h3>

<p>The structures of OTP applications and of OTP releases are different. An OTP application
can be expected to have one top-level supervisor (if any) and possibly a bunch of
dependencies that sit below it. An OTP release will usually be composed of multiple OTP applications, which may or may not depend on each other. This will lead to two major
ways to lay out applications.</p>

<h4>OTP Applications</h4>
<p>For OTP applications, the proper structure is pretty much the same as what was explained
in 1.2:</p>

<blockquote>
	1 doc/
2 deps/
3 ebin/
4 src/
5 test/
6 LICENSE.txt
7 README.md
8 rebar.config
</blockquote>

<p>What’s new in this one is the deps/ directory, which is fairly useful to have, but that
will be generated automatically by rebar2 if necessary. That’s because there is no canonical
package management in Erlang. People instead adopted rebar, which fetches dependencies
locally, on a per-project basis. This is fine and removes a truckload of conflicts, but means
that each project you have may have to download its own set of dependencies</p>

<p>This is accomplished with rebar by adding a few config lines to rebar.config:</p>

<blockquote>
	
	1 {deps,
2 [{application_name, "1.0.*",
3 {git, "git://github.com/user/myapp.git", {branch,"master"}}},
4 {application_name, "2.0.1",
5 {git, "git://github.com/user/hisapp.git", {tag,"2.0.1"}}},
6 {application_name, "",
7 {git, "https://bitbucket.org/user/herapp.git", "7cd0aef4cd65"}},
8 {application_name, "my regex",
9 {hg, "https://bitbucket.org/user/theirapp.hg" {branch, "stable"}}}]}.
</blockquote>

<sub>
	2A lot of people package rebar directly in their application. This was initially done to help people who
had never used rebar before use libraries and projects in a boostrapped manner. Feel free to install rebar
globally on your system, or keep a local copy if you require a specific version to build your system.
</sub>

<p>Applications are fetched directly from a git (or hg, or svn) source, recursively. They can
then be compiled, and specific compile options can be added with the {erl_opts, List}.
option in the config file3.</p>

<p>Within these directories, you can do your regular development of an OTP application.
To compile them, call rebar get-deps compile, which will download all dependencies,
and then build them and your app at once.</p>

<p>When making your application public to the world, distribute it without the dependencies.
It’s quite possible that other developers’ applications depend on the same applications
yours do, and it’s no use shipping them all multiple times. The build system in place (in this
case, rebar) should be able to figure out duplicated entries and fetch everything necessary
only once.</p>

<h4>OTP Releases</h4>

<p>For releases, the structure should be a bit different4. Releases are collections of applications,
and their structures should reflect that</p>

<p>Instead of having a top-level app, applications should be nested one level deeper and
divided into two categories: apps and deps. The apps directory contains your applications’
source code (say, internal business code), and the deps directory contains independently
managed dependency applications.</p>

<blockquote>
apps/
doc/
deps/
LICENSE.txt
README.md
rebar.config
</blockquote>

<p>This structure lends itself to generating releases. Tools such as Systool and Reltool have
been covered before5, and can allow the user plenty of power. An easier tool that recently
appeared is relx6.</p>

<p>A relx configuration file for the directory structure above would look like:</p>
<blockquote>1 {paths, ["apps", "deps"]}.
2 {include_erts, false}. % will use currently installed Erlang
3 {default_release, demo, "1.0.0"}.
4
5 {release, {demo, "1.0.0"},
6 [members,
7 feedstore,
8 ...
9 recon]}.</blockquote>
<sub>
	<br/>3More details by calling rebar help compile
<br/>4I say should because many Erlang developers put their final system under a single top-level application
(in src) and a bunch of follower ones as dependencies (in deps), which is less than ideal for distribution
purposes and conflicts with assumptions on directory structures made by OTP. People who do that tend
to build from source on the production servers and run custom commands to boot their applications.
<br/>5http://learnyousomeerlang.com/release-is-the-word
<br/>6https://github.com/erlware/relx/wiki
</sub>

<p>Calling ./relx (if the executable is in the current directory) will build a release, to be
found in the _rel/ directory. If you really like using rebar, you can build a release as part
of the project’s compilation by using a rebar hook in rebar.config:</p>

<blockquote>
	
	1 {post_hooks,[{compile, "./relx"}]}.
</blockquote>

<p>
	And every time rebar compile will be called, the release will be generated.
</p>
<h3>Supervisors and start_link Semantics</h3>

<p>In complex production systems, most faults and errors are transient, and retrying an operation
is a good way to do things — Jim Gray’s paper7 quotes Mean Times Between Failures
(MTBF) of systems handling transient bugs being better by a factor of 4 when doing this.
Still, supervisors aren’t just about restarting</p>

<p>One very important part of Erlang supervisors and their supervision trees is that their
start phases are synchronous. Each OTP process has the potential to prevent its siblings
and cousins from booting. If the process dies, it’s retried again, and again, until it works,
or fails too often.</p>

<p>That’s where people make a very common mistake. There isn’t a backoff or cooldown
period before a supervisor restarts a crashed child. When a network-based application tries
to set up a connection during its initialization phase and the remote service is down, the
application fails to boot after too many fruitless restarts. Then the system may shut down.</p>

<p>Many Erlang developers end up arguing in favor of a supervisor that has a cooldown
period. I strongly oppose the sentiment for one simple reason: it’s all about the guarantees.</p>

<h4>It’s About the Guarantees</h4>

<p>Restarting a process is about bringing it back to a stable, known state. From there, things
can be retried. When the initialization isn’t stable, supervision is worth very little. An initialized process should be stable no matter what happens. That way, when its siblings
and cousins get started later on, they can be booted fully knowing that the rest of the
system that came up before them is healthy.</p>

<sub>7http://mononcqc.tumblr.com/post/35165909365/why-do-computers-stop</sub>

<p>If you don’t provide that stable state, or if you were to start the entire system asynchronously,
you would get very little benefit from this structure that a try ... catch in
a loop wouldn’t provide.</p>

<p>Supervised processes provide guarantees in their initialization phase, not a best effort.
This means that when you’re writing a client for a database or service, you shouldn’t need
a connection to be established as part of the initialization phase unless you’re ready to say
it will always be available no matter what happens.</p>
<p>You could force a connection during initialization if you know the database is on the
same host and should be booted before your Erlang system, for example. Then a restart
should work. In case of something incomprehensible and unexpected that breaks these
guarantees, the node will end up crashing, which is desirable: a pre-condition to starting
your system hasn’t been met. It’s a system-wide assertion that failed.</p>

<p>If, on the other hand, your database is on a remote host, you should expect the connection
to fail. It’s just a reality of distributed systems that things go down.8 In this
case, the only guarantee you can make in the client process is that your client will be
able to handle requests, but not that it will communicate to the database. It could return
{error, not_connected} on all calls during a net split, for example.</p>

<p>The reconnection to the database can then be done using whatever cooldown or backoff
strategy you believe is optimal, without impacting the stability of the system. It can be
attempted in the initialization phase as an optimization, but the process should be able to
reconnect later on if anything ever disconnects.</p>

<p>If you expect failure to happen on an external service, do not make its presence a
guarantee of your system. We’re dealing with the real world here, and failure of external
dependencies is always an option.</p>

<h4>Side Effects</h4>
<p>Of course, the libraries and processes that call such a client will then error out if they don’t
expect to work without a database. That’s an entirely different issue in a different problem
space, one that depends on your business rules and what you can or can’t do to a client,
but one that is possible to work around. For example, consider a client for a service that
stores operational metrics — the code that calls that client could very well ignore the errors
without adverse effects to the system as a whole.</p>

<p>The difference in both initialization and supervision approaches is that the client’s
callers make the decision about how much failure they can tolerate, not the client itself.
That’s a very important distinction when it comes to designing fault-tolerant systems. Yes,
supervisors are about restarts, but they should be about restarts to a stable known state.</p>

<sub>8Or latency shoots up enough that it is impossible to tell the difference from failure.</sub>

<h4>Example: Initializing without guaranteeing connections</h4>

<p>The following code attempts to guarantee a connection as part of the process’ state:</p>

<blockquote>
	1 init(Args) ->
2 Opts = parse_args(Args),
3 {ok, Port} = connect(Opts),
4 {ok, #state{sock=Port, opts=Opts}}.
5
6 [...]
7
8 handle_info(reconnect, S = #state{sock=undefined, opts=Opts}) ->
9 %% try reconnecting in a loop
10 case connect(Opts) of
11 {ok, New} -> {noreply, S#state{sock=New}};
12 _ -> self() ! reconnect, {noreply, S}
13 end;
</blockquote>

<p>Instead, consider rewriting it as:</p>

<blockquote>
	1 init(Args) ->
2 Opts = parse_args(Args),
3 %% you could try connecting here anyway, for a best
4 %% effort thing, but be ready to not have a connection.
5 self() ! reconnect,
6 {ok, #state{sock=undefined, opts=Opts}}.
7
8 [...]
9
10 handle_info(reconnect, S = #state{sock=undefined, opts=Opts}) ->
11 %% try reconnecting in a loop
12 case connect(Opts) of
13 {ok, New} -> {noreply, S#state{sock=New}};
14 _ -> self() ! reconnect, {noreply, S}
15 end;
</blockquote>
<p>You now allow initializations with fewer guarantees: they went from the connection is
available to the connection manager is available.</p>

<h4>In a nutshell</h4>
<p>Production systems I have worked with have been a mix of both approaches.
Things like configuration files, access to the file system (say for logging purposes), local
resources that can be depended on (opening UDP ports for logs), restoring a stable state
from disk or network, and so on, are things I’ll put into requirements of a supervisor and
may decide to synchronously load no matter how long it takes (some applications may
just end up having over 10 minute boot times in rare cases, but that’s okay because we’re
possibly syncing gigabytes that we need to work with as a base state if we don’t want to
serve incorrect information.)</p>

<p>On the other hand, code that depends on non-local databases and external services
will adopt partial startups with quicker supervision tree booting because if the failure is
expected to happen often during regular operations, then there’s no difference between now
and later. You have to handle it the same, and for these parts of the system, far less strict
guarantees are often the better solution.</p>

<h4>Application Strategies</h4>
<p>No matter what, a sequence of failures is not a death sentence for the node. Once a system
has been divided into various OTP applications, it becomes possible to choose which applications
are vital or not to the node. Each OTP application can be started in 3 ways: temporary,
transient, permanent, either by doing it manually in application:start(Name, Type),
or in the config file for your release:</p>

<ul>
	<li>permanent: if the app terminates, the entire system is taken down, excluding manual
termination of the app with application:stop/1</li>
	<li>transient: if the app terminates for reason normal, that’s ok. Any other reason for
termination shuts down the entire system.</li>
	<li>temporary: the application is allowed to stop for any reason. It will be reported, but
nothing bad will happen.</li>
</ul>
<p>It is also possible to start an application as an included application, which starts it under
your own OTP supervisor with its own strategy to restart it.</p>

<h3>Exercises</h3>
<h4>Review Questions</h4>
<ol>
	<li>Are Erlang supervision trees started depth-first? breadth-first? Synchronously or
asynchronously?</li>
	<li>What are the three application strategies? What do they do?</li>
	<li>What are the main differences between the directory structure of an app and a release?</li>
	<li>When should you use a release?</li>
	<li>Give two examples of the type of state that can go in a process’ init function, and
two examples of the type of state that shouldn’t go in a process’ init function</li>
</ol>
<h4>Hands-On</h4>
<p>Using the code at https://github.com/ferd/recon_demo:</p>

<ol>
	<li>Extract the main application hosted in the release to make it independent, and includable
in other projects.</li>
	<li>Host the application somewhere (Github, Bitbucket, local server), and build a release
with that application as a dependency.</li>
	<li>The main application’s workers (council_member) starts a server and connects to
it in its init/1 function. Can you make this connection happen outside of the init
function’s? Is there a benefit to doing so in this specific case?</li>
</ol>
<h2>Chapter 3</h2>
<h2>Planning for Overload</h2>
<p>By far, the most common cause of failure I’ve encountered in real-world scenarios is due
to the node running out of memory. Furthermore, it is usually related to message queues
going out of bounds.1 There are plenty of ways to deal with this, but knowing which one
to use will require a decent understanding of the system you’re working on.</p>

<p>To oversimplify things, most of the projects I end up working on can be visualized
as a very large bathroom sink. User and data input are flowing from the faucet. The
Erlang system itself is the sink and the pipes, and wherever the output goes (whether it’s
a database, an external API or service, and so on) is the sewer system.</p>
<img src="images/sink.png">
<p>When an Erlang node dies because of a queue overflowing, figuring out who to blame is
crucial. Did someone put too much water in the sink? Are the sewer systems backing up ? Did you just design too small a pipe?</p>
<sub>1Figuring out that a message queue is the problem is explained in Chapter 6, specifically in Section 6.2</sub>

<p>Determining what queue blew up is not necessarily hard. This is information that can
be found in a crash dump. Finding out why it blew up is trickier. Based on the role of
the process or run-time inspection, it’s possible to figure out whether causes include fast
flooding, blocked processes that won’t process messages fast enough, and so on.</p>

<p>The most difficult part is to decide how to fix it. When the sink gets clogged up by
too much waste, we will usually start by trying to make the bathroom sink itself larger
(the part of our program that crashed, at the edge). Then we figure out the sink’s drain is
too small, and optimize that. Then we find out the pipes themselves are too narrow, and
optimize that. The overload gets pushed further down the system, until the sewers can’t
take it anymore. At that point, we may try to add sinks or add bathrooms to help with
the global input level.</p>

<p>Then there’s a point where things can’t be improved anymore at the bathroom’s level.
There are too many logs sent around, there’s a bottleneck on databases that need the
consistency, or there’s simply not enough knowledge or manpower in your organization to
improve things there.</p>

<p>By finding that point, we identified what the true bottleneck of the system was, and all
the prior optimization was nice (and likely expensive), but it was more or less in vain.</p>

<p>We need to be more clever, and so things are moved back up a level. We try to
massage the information going in the system to make it either lighter (whether it is through
compression, better algorithms and data representation, caching, and so on).</p>

<p>Even then, there are times where the overload will be too much, and we have to make the
hard decisions between restricting the input to the system, discarding it, or accepting that
the system will reduce its quality of service up to the point it will crash. These mechanisms
fall into two broad strategies: back-pressure and load-shedding.</p>

<p>We’ll explore them in this chapter, along with common events that end up causing
Erlang systems to blow up.</p>

<h3>Common Overload Sources</h3>
<p>There are a few common causes of queues blowing up and overload in Erlang systems that
most people will encounter sooner or later, no matter how they approach their system.
They’re usually symptomatic of having your system grow up and require some help scaling
up, or of an unexpected type of failure that ends up cascading much harder than it should
have.</p>
<h4>error_logger Explodes</h4>
<p>Ironically, the process in charge of error logging is one of the most fragile ones. In a default
Erlang install, the error_logger2 process will take its sweet time to log things to disk or
over the network, and will do so much more slowly than errors can be generated.</p>

<p>This is especially true of user-generated log messages (not for errors), and for crashes in
large processes. For the former, this is because error_logger doesn’t really expect arbitrary
levels of messages coming in continually. It’s for exceptional cases only and doesn’t expect
lots of traffic. For the latter, it’s because the entire state of processes (including their
mailboxes) gets copied over to be logged. It only takes a few messages to cause memory to
bubble up a lot, and if that’s not enough to cause the node to run Out Of Memory (OOM),
it may slow the logger enough that additional messages will.</p>
<p>The best solution for this at the time of writing is to use lager as a substitute logging
library.</p>
<p>While lager will not solve all your problems, it will truncate voluminous log messages,
optionally drop OTP-generated error messages when they go over a certain threshold, and
will automatically switch between asynchronous and synchronous modes for user-submitted
messages in order to self-regulate.</p>
<p>It won’t be able to deal with very specific cases, such as when user-submitted messages
are very large in volume and all coming from one-off processes. This is, however, a much
rarer occurrence than everything else, and one where the programmer tends to have more
control.</p>
<h3>Locks and Blocking Operations</h3>
<p>Locking and blocking operations will often be problematic when they’re taking unexpectedly
long to execute in a process that’s constantly receiving new tasks.</p>

<p>One of the most common examples I’ve seen is a process blocking while accepting a
connection or waiting for messages with TCP sockets. During blocking operations of this
kind, messages are free to pile up in the message queue.</p>

<p>One particularly bad example was in a pool manager for HTTP connections that I had
written in a fork of the lhttpc library. It worked fine in most test cases we had, and we
even had a connection timeout set to 10 milliseconds to be sure it never took too long3.
After a few weeks of perfect uptime, the HTTP client pool caused an outage when one of
the remote servers went down.</p>

<p>The reason behind this degradation was that when the remote server would go down, all
of a sudden, all connecting operations would take at least 10 milliseconds, the time before
which the connection attempt is given up on. With around 9,000 messages per second to the central process, each usually taking under 5 milliseconds, the impact became similar to
roughly 18,000 messages a second and things got out of hand.</p>

<sub>
	<br/>2Defined at http://www.erlang.org/doc/man/error_logger.html
<br/>310 milliseconds is very short, but was fine for collocated servers used for real-time bidding.
</sub>

<p>The solution we came up with was to leave the task of connecting to the caller process,
and enforce the limits as if the manager had done it on its own. The blocking operations
were now distributed to all users of the library, and even less work was required to be done
by the manager, now free to accept more requests.</p>

<p>When there is any point of your program that ends up being a central hub for receiving
messages, lengthy tasks should be moved out of there if possible. Handling predictable overload4
situations by adding more processes — which either handle the blocking operations
or instead act as a buffer while the "main" process blocks — is often a good idea.</p>

<p>There will be increased complexity in managing more processes for activities that aren’t
intrinsically concurrent, so make sure you need them before programming defensively.</p>

<p>Another option is to transform the blocking task into an asynchronous one. If the type
of work allows it, start the long-running job and keep a token that identifies it uniquely,
along with the original requester you’re doing work for. When the resource is available,
have it send a message back to the server with the aforementioned token. The server will
eventually get the message, match the token to the requester, and answer back, without
being blocked by other requests in the mean time.5</p>

<p>This option tends to be more obscure than using many processes and can quickly devolve
into callback hell, but may use fewer resources.</p>

<h4>Unexpected Messages</h4>
<p>Messages you didn’t know about tend to be rather rare when using OTP applications.
Because OTP behaviours pretty much expect you to handle anything with some clause in
handle_info/2, unexpected messages will not accumulate much.</p>
<p>However, all kinds of OTP-compliant systems end up having processes that may not
implement a behaviour, or processes that go in a non-behaviour stretch where it overtakes
message handling. If you’re lucky enough, monitoring tools6 will show a constant memory
increase, and inspecting for large queue sizes7 will let you find which process is at fault.
You can then fix the problem by handling the messages as required.</p>

<sub>
	<br/>4Something you know for a fact gets overloaded in production
	<br/>5The redo application is an example of a library doing this, in its redo_block module. The [underdocumented]
module turns a pipelined connection into a blocking one, but does so while maintaining pipeline
aspects to the caller — this allows the caller to know that only one call failed when a timeout occurs, not
all of the in-transit ones, without having the server stop accepting requests.
	<br/>6See Section 5.1
	<br/>7See Subsection 5.2.1
</sub>

<h3>Restricting Input
</h3>
<p>Restricting input is the simplest way to manage message queue growth in Erlang systems.
It’s the simplest approach because it basically means you’re slowing the user down (applying
back-pressure), which instantly fixes the problem without any further optimization required.
On the other hand, it can lead to a really crappy experience for the user.
</p>
<p>The most common way to restrict data input is to make calls to a process whose queue
would grow in uncontrollable ways synchronously. By requiring a response before moving
on to the next request, you will generally ensure that the direct source of the problem will
be slowed down.
</p>
<p>The difficult part for this approach is that the bottleneck causing the queue to grow is
usually not at the edge of the system, but deep inside it, which you find after optimizing
nearly everything that came before. Such bottlenecks will often be database operations,
disk operations, or some service over the network.
</p>
<p>This means that when you introduce synchronous behaviour deep in the system, you’ll
possibly need to handle back-pressure, level by level, until you end up at the system’s edges
and can tell the user, "please slow down." Developers that see this pattern will often try to
put API limits per user8 on the system entry points. This is a valid approach, especially
since it can guarantee a basic quality of service (QoS) to the system and allows one to
allocate resources as fairly (or unfairly) as desired.
</p>
<h4> How Long Should a Time Out Be
</h4>
<p>What’s particularly tricky about applying back-pressure to handle overload via synchronous
calls is having to determine what the typical operation should be taking in terms of time,
or rather, at what point the system should time out.
</p>
<p>The best way to express the problem is that the first timer to be started will be at
the edge of the system, but the critical operations will be happening deep within it. This
means that the timer at the edge of the system will need to have a longer wait time that
those within, unless you plan on having operations reported as timing out at the edge even
though they succeeded internally.
</p>
<p>An easy way out of this is to go for infinite timeouts. Pat Helland9 has an interesting
answer to this:
</p>
<blockquote>
	Some application developers may push for no timeout and argue it is OK to
wait indefinitely. I typically propose they set the timeout to 30 years. That, in
turn, generates a response that I need to be reasonable and not silly. Why is 30
years silly but infinity is reasonable? I have yet to see a messaging application
that really wants to wait for an unbounded period of time. . .
</blockquote>
<sub>8
There’s a tradeoff between slowing down all requests equally or using rate-limiting, both of which are
valid. Rate-limiting per user would mean you’d still need to increase capacity or lower the limits of all users
when more new users hammer your system, whereas a synchronous system that indiscriminately blocks
should adapt to any load with more ease, but possibly unfairly.
<br/>9
Idempotence is Not a Medical Condition, April 14, 2012
</sub>
<p>This is, ultimately, a case-by-case issue. In many cases, it may be more practical to use
a different mechanism for that flow control.10
</p>
<h4>Asking For Permission
</h4>
<p>A somewhat simpler approach to back-pressure is to identify the resources we want to block
on, those that cannot be made faster and are critical to your business and users. Lock these
resources behind a module or procedure where a caller must ask for the right to make a
request and use them. There’s plenty of variables that can be used: memory, CPU, overall
load, a bounded number of calls, concurrency, response times, a combination of them, and
so on.
</p>
<p>The SafetyValve 11 application is a system-wide framework that can be used when you
know back-pressure is what you’ll need.
</p>
<p>For more specific use cases having to do with service or system failures, there are plenty
of circuit breaker applications available. Examples include breaky12 , fuse13, or Klarna’s
circuit_breaker14 .
</p>
<p>Otherwise, ad-hoc solutions can be written using processes, ETS, or any other tool
available. The important part is that the edge of the system (or subsystem) may block and
ask for the right to process data, but the critical bottleneck in code is the one to determine
whether that right can be granted or not.
</p>
<p>The advantage of proceeding that way is that you may just avoid all the tricky stuff
about timers and making every single layer of abstraction synchronous. You’ll instead put
guards at the bottleneck and at a given edge or control point, and everything in between
can be expressed in the most readable way possible.
</p>
<h4> What Users See</h4>
<p>The tricky part about back-pressure is reporting it. When back-pressure is done implicitly
through synchronous calls, the only way to know it is at work due to overload is that the
system becomes slower and less usable. Sadly, this is also going to be a potential symptom
of bad hardware, bad network, unrelated overload, and possibly a slow client.
</p>
<p>Trying to figure out that a system is applying back-pressure by measuring its respon-
siveness is equivalent to trying to diagnose which illness someone has by observing that
person has a fever. It tells you something is wrong, but not what.
</p>
<sub>10
In Erlang, using the value infinity will avoid creating a timer, avoiding some resources. If you do
use this, remember to at least have a well-defined timeout somewhere in the sequence of calls.
<br/>11
https://github.com/jlouis/safetyvalve
<br/>12
https://github.com/mmzeeman/breaky
<br/>13
https://github.com/jlouis/fuse
<br/>14
https://github.com/klarna/circuit_breaker
</sub>

<p>Asking for permission, as a mechanism, will generally allow you to define your interface
in such a way that you can explicitly report what is going on: the system as a whole is
overloaded, or you’re hitting a limit into the rate at which you can perform an operation
and adjust accordingly.
</p>
<p>There is a choice to be made when designing the system. Are your users going to have
per-account limits, or are the limits going to be global to the system?
</p>
<p>System-global or node-global limits are usually easy to implement, but will have the
downside that they may be unfair. A user doing 90% of all your requests may end up
making the platform unusable for the vast majority of the other users.
</p>
<p>Per-account limits, on the other hand, tend to be very fair, and allow fancy schemes
such as having premium users who can go above the usual limits. This is extremely nice,
but has the downside that the more users use your system, the higher the effective global
system limit tends to move. Starting with 100 users that can do 100 requests a minute gives
you a global 10000 requests per minute. Add 20 new users with that same rate allowed,
and suddenly you may crash a lot more often.
</p>
<p>The safe margin of error you established when designing the system slowly erodes as
more people use it. It’s important to consider the tradeoffs your business can tolerate from
that point of view, because users will tend not to appreciate seeing their allowed usage go
down all the time, possibly even more so than seeing the system go down entirely from time
to time.
</p>
<h3>3.3
 Discarding Data
</h3>
<p>When nothing can slow down outside of your Erlang system and things can’t be scaled up,
you must either drop data or crash (which drops data that was in flight, for most cases,
but with more violence).
</p>
<p>It’s a sad reality that nobody really wants to deal with. Programmers, software engi-
neers, and computer scientists are trained to purge the useless data, and keep everything
that’s useful. Success comes through optimization, not giving up.
</p>
<p>However, there’s a point that can be reached where the data that comes in does so at a
rate faster than it goes out, even if the Erlang system on its own is able to do everything
fast enough. In some cases, It’s the component after it that blocks.
</p>
<p>If you don’t have the option of limiting how much data you receive, you then have to
drop messages to avoid crashing.
</p>
<h4>Random Drop
</h4>
<p>Randomly dropping messages is the easiest way to do such a thing, and might also be the
most robust implementation, due to its simplicity.
</p>
<p>The trick is to define some threshold value between 0.0 and 1.0 and to fetch a random
number in that range:
</p>
<blockquote>
	-module(drop).
-export([random/1]).
random(Rate) ->
maybe_seed(),
random:uniform() =< Rate.
maybe_seed() ->
case get(random_seed) of
undefined -> random:seed(erlang:now());
{X,X,X} -> random:seed(erlang:now());
_ -> ok
end.

</blockquote>
<p>If you aim to keep 95% of the messages you send, the authorization could be written
by a call to case drop:random(0.95) of true -> send(); false -> drop() end, or a
shorter drop:random(0.95) andalso send() if you don’t need to do anything specific
when dropping a message.
</p>
<p>The maybe_seed() function will check that a valid seed is present in the process dic-
tionary and use it rather than a crappy one, but only if it has not been defined before, in
order to avoid calling now() (a monotonic function that requires a global lock) too often.
</p>
<p>There is one ‘gotcha’ to this method, though: the random drop must ideally be done
at the producer level rather than at the queue (the receiver) level. The best way to avoid
overloading a queue is to not send data its way in the first place. Because there are no
bounded mailboxes in Erlang, dropping in the receiving process only guarantees that this
process will be spinning wildly, trying to get rid of messages, and fighting the schedulers to
do actual work.
</p>
<p>On the other hand, dropping at the producer level is guaranteed to distribute the work
equally across all processes.
</p>
<p>This can give place to interesting optimizations where the working process or a given
monitor process15 uses values in an ETS table or application:set_env/3 to dynamically
increase and decrease the threshold to be used with the random number. This allows control
over how many messages are dropped based on overload, and the configuration data can be
fetched by any process rather efficiently by using application:get_env/2.
</p>
<p>Similar techniques could also be used to implement different drop ratios for different
message priorities, rather than trying to sort it all out at the consumer level.
</p>
<sub>15
Any process tasked with checking the load of specific processes using heuristics such as
process_info(Pid, message_queue_len) could be a monitor
</sub>
<h4>Queue Buffers
</h4>
<p>Queue buffers are a good alternative when you want more control over the messages you
get rid of than with random drops, particularly when you expect overload to be coming in
bursts rather than a constant stream in need of thinning.
</p>
<p>Even though the regular mailbox for a process has the form of a queue, you’ll generally
want to pull all the messages out of it as soon as possible. A queue buffer will need two
processes to be safe:
</p>
<ul>
	<li>The regular process you’d work with (likely a gen_server);
</li>
	<li>A new process that will do nothing but buffer the messages. Messages from the
outside should go to this process.
</li>
</ul>
<p>To make things work, the buffer process only has to remove all the messages it can from
its mail box and put them in a queue data structure16 it manages on its own. Whenever
the server is ready to do more work, it can ask the buffer process to send it a given number
of messages that it can work on. The buffer process picks them from its queue, forwards
them to the server, and goes back to accumulating data.
</p>
<p>Whenever the queue grows beyond a certain size17 and you receive a new message, you
can then pop the oldest one and push the new one in there, dropping the oldest elements
as you go.18
</p>
<p>This should keep the entire number of messages received to a rather stable size and
provide a good amount of resistance to overload, somewhat similar to the functional version
of a ring buffer.
</p>
<p>The PO Box 19 library implements such a queue buffer.
</p>
<h4> Stack Buffers
</h4>
<p>Stack buffers are ideal when you want the amount of control offered by queue buffers, but
you have an important requirement for low latency.
</p>
<p>To use a stack as a buffer, you’ll need two processes, just like you would with queue
buffers, but a list20 will be used instead of a queue data structure.
</p>
<sub>
	16
The queue module in Erlang provides a purely functional queue data structure that can work fine for
such a buffer.
<br/>17
To calculate the length of a queue, it is preferable to use a counter that gets incremented and decre-
mented on each message sent or received, rather than iterating over the queue every time. It takes slightly
more memory, but will tend to distribute the load of counting more evenly, helping predictability and
avoiding more sudden build-ups in the buffer’s mailbox
<br/>18
You can alternatively make a queue that pops the newest message and queues up the oldest ones if you
feel previous data is more important to keep.
<br/>19
Available at: https://github.com/ferd/pobox, the library has been used in production for a long time
in large scale products at Heroku and is considered mature
<br/>20
Erlang lists are stacks, for all we care. They provide push and pop operations that take O(1) complexity
and are very fast

</sub>
<p>The reason the stack buffer is particularly good for low latency is related to issues
similar to bufferbloat21. If you get behind on a few messages being buffered in a queue,
all the messages in the queue get to be slowed down and acquire milliseconds of wait time.
Eventually, they all get to be too old and the entire buffer needs to be discarded.
</p>
<p>On the other hand, a stack will make it so only a restricted number of elements are
kept waiting while the newer ones keep making it to the server to be processed in a timely
manner.
</p>
<p>Whenever you see the stack grow beyond a certain size or notice that an element in it
is too old for your QoS requirements you can just drop the rest of the stack and keep going
from there. PO Box also offers such a buffer implementation.
</p>
<p>A major downside of stack buffers is that messages are not necessarily going to be
processed in the order they were submitted — they’re nicer for independent tasks, but will
ruin your day if you expect a sequence of events to be respected.
</p>
<h4>Time-Sensitive Buffers
</h4>
<p>If you need to react to old events before they are too old, then things become more complex,
as you can’t know about it without looking deep in the stack each time, and dropping from
the bottom of the stack in a constant manner gets to be inefficient. An interesting approach
could be done with buckets, where multiple stacks are used, with each of them containing a
given time slice. When requests get too old for the QoS constraints, drop an entire bucket,
but not the entire buffer.
</p>
<p>It may sound counter-intuitive to make some requests a lot worse to benefit the majority
— you’ll have great medians but poor 99 percentiles — but this happens in a state where
you would drop messages anyway, and is preferable in cases where you do need low latency.
</p>
<h4>Dealing With Constant Overload
</h4>
<p>Being under constant overload may require a new solution. Whereas both queues and
buffers will be great for cases where overload happens from time to time (even if it’s a
rather prolonged period of time), they both work more reliably when you expect the input
rate to eventually drop, letting you catch up.
</p>
<p>You’ll mostly get problems when trying to send so many messages they can’t make it
all to one process without overloading it. Two approaches are generally good for this case:
</p>
<ul>
	<li>Have many processes that act as buffers and load-balance through them (scale horizontally)
</li>
	<li>use ETS tables as locks and counters (reduce the input)
</li>
</ul>
<p>ETS tables are generally able to handle a ton more requests per second than a process,
but the operations they support are a lot more basic. A single read, or adding or removing from a counter atomically is as fancy as you should expect things to get for the general
case.

</p>
<sub>21
http://queue.acm.org/detail.cfm?id=2071893
</sub>
<p>ETS tables will be required for both approaches.
</p>
<p>Generally speaking, the first approach could work well with the regular process registry:
you take N processes to divide up the load, give them all a known name, and pick one
of them to send the message to. Given you’re pretty much going to assume you’ll be
overloaded, randomly picking a process with an even distribution tends to be reliable: no
state communication is required, work will be shared in a roughly equal manner, and it’s
rather insensitive to failure.
</p>
<p>In practice, though, we want to avoid atoms generated dynamically, so I tend to prefer
to register workers in an ETS table with read_concurrency set to true. It’s a bit more
work, but it gives more flexibility when it comes to updating the number of workers later
on.
</p>
<p>An approach similar to this one is used in the lhttpc22 library mentioned earlier, to
split load balancers on a per-domain basis.
</p>
<p>For the second approach, using counters and locks, the same basic structure still remains
(pick one of many options, send it a message), but before actually sending a message, you
must atomically update an ETS counter23 . There is a known limit shared across all clients
(either through their supervisor, or any other config or ETS value) and each request that
can be made to a process needs to clear this limit first.
</p>
<p>This approach has been used in dispcount24 to avoid message queues, and to guarantee
low-latency responses to any message that won’t be handled so that you do not need to
wait to know your request was denied. It is then up to the user of the library whether to
give up as soon as possible, or to keep retrying with different workers.
</p>
<h4>How Do You Drop
</h4>
<p>Most of the solutions outlined here work based on message quantity, but it’s also possible
to try and do it based on message size, or expected complexity, if you can predict it. When
using a queue or stack buffer, instead of counting entries, all you may need to do is count
their size or assign them a given load as a limit.
</p>
<p>I’ve found that in practice, dropping without regard to the specifics of the message
works rather well, but each application has its share of unique compromises that can be
acceptable or not25 .
</p>
<sub>
	22
The lhttpc_lb module in this library implements it.
<br/>23
By using ets:update_counter/3.
<br/>24
https://github.com/ferd/dispcount
<br/>25
Old papers such as Hints for Computer System Designs by Butler W. Lampson recommend dropping
messages: "Shed load to control demand, rather than allowing the system to become overloaded." The
paper also mentions that "A system cannot be expected to function well if the demand for any resource
exceeds two-thirds of the capacity, unless the load can be characterized extremely well." adding that "The
only systems in which cleverness has worked are those with very well-known loads."

</sub>
<p>There are also cases where the data is sent to you in a "fire and forget" manner —
the entire system is part of an asynchronous pipeline — and it proves difficult to provide
feedback to the end-user about why some requests were dropped or are missing. If you can
reserve a special type of message that accumulates dropped responses and tells the user "N
messages were dropped for reason X", that can, on its own, make the compromise far more
acceptable to the user. This is the choice that was made with Heroku’s logplex log routing
system, which can spit out L10 errors, alerting the user that a part of the system can’t deal
with all the volume right now.
</p>
<p>In the end, what is acceptable or not to deal with overload tends to depend on the
humans that use the system. It is often easier to bend the requirements a bit than develop
new technology, but sometimes it is just not avoidable.
</p>
<h3>Exercises</h3>
<h4>Review Questions
</h4>
<ol>
<li>Name the common sources of overload in Erlang systems
</li>
<li>What are the two main classes of strategies to handle overload?
</li>
<li>How can long-running operations be made safer?
</li>
<li>When going synchronous, how should timeouts be chosen?
</li>
<li>What is an alternative to having timeouts?
</li>
<li>When would you pick a queue buffer before a stack buffer?
</li>
</ol>
<h4>Open-ended Questions
</h4>
<ol>
	<li>What is a true bottleneck ? How can you find it?
In an application that calls a third party API, response times vary by a lot depending
on how healthy the other servers are. How could one design the system to prevent
occasionally slow requests from blocking other concurrent calls to the same service?
</li>
	<li>What’s likely to happen to new requests to an overloaded latency-sensitive service
where data has backed up in a stack buffer? What about old requests?
</li>
	<li>Explain how you could turn a load-shedding overload mechanism into one that can
also provide back-pressure.
</li>
	<li>Explain how you could turn a back-pressure mechanism into a load-shedding mecha-
nism.
</li>
	<li>What are the risks, for a user, when dropping or blocking a request? How can we
prevent duplicate messages or missed ones?
</li>
	<li>What can you expect to happen to your API design if you forget to deal with overload,
and suddenly need to add back-pressure or load-shedding to it?
</li>
</ol>	
</body>
</html>